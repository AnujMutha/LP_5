{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9cfb5e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e3d1cb8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Boston_House_Prices.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d0bc0371",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>MEDV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>0.06263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.593</td>\n",
       "      <td>69.1</td>\n",
       "      <td>2.4786</td>\n",
       "      <td>1</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>391.99</td>\n",
       "      <td>9.67</td>\n",
       "      <td>22.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>0.04527</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.120</td>\n",
       "      <td>76.7</td>\n",
       "      <td>2.2875</td>\n",
       "      <td>1</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.08</td>\n",
       "      <td>20.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>0.06076</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.976</td>\n",
       "      <td>91.0</td>\n",
       "      <td>2.1675</td>\n",
       "      <td>1</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.64</td>\n",
       "      <td>23.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>0.10959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.794</td>\n",
       "      <td>89.3</td>\n",
       "      <td>2.3889</td>\n",
       "      <td>1</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>393.45</td>\n",
       "      <td>6.48</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>0.04741</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.030</td>\n",
       "      <td>80.8</td>\n",
       "      <td>2.5050</td>\n",
       "      <td>1</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>7.88</td>\n",
       "      <td>11.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>506 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0    0.00632  18.0   2.31     0  0.538  6.575  65.2  4.0900    1  296.0   \n",
       "1    0.02731   0.0   7.07     0  0.469  6.421  78.9  4.9671    2  242.0   \n",
       "2    0.02729   0.0   7.07     0  0.469  7.185  61.1  4.9671    2  242.0   \n",
       "3    0.03237   0.0   2.18     0  0.458  6.998  45.8  6.0622    3  222.0   \n",
       "4    0.06905   0.0   2.18     0  0.458  7.147  54.2  6.0622    3  222.0   \n",
       "..       ...   ...    ...   ...    ...    ...   ...     ...  ...    ...   \n",
       "501  0.06263   0.0  11.93     0  0.573  6.593  69.1  2.4786    1  273.0   \n",
       "502  0.04527   0.0  11.93     0  0.573  6.120  76.7  2.2875    1  273.0   \n",
       "503  0.06076   0.0  11.93     0  0.573  6.976  91.0  2.1675    1  273.0   \n",
       "504  0.10959   0.0  11.93     0  0.573  6.794  89.3  2.3889    1  273.0   \n",
       "505  0.04741   0.0  11.93     0  0.573  6.030  80.8  2.5050    1  273.0   \n",
       "\n",
       "     PTRATIO       B  LSTAT  MEDV  \n",
       "0       15.3  396.90   4.98  24.0  \n",
       "1       17.8  396.90   9.14  21.6  \n",
       "2       17.8  392.83   4.03  34.7  \n",
       "3       18.7  394.63   2.94  33.4  \n",
       "4       18.7  396.90   5.33  36.2  \n",
       "..       ...     ...    ...   ...  \n",
       "501     21.0  391.99   9.67  22.4  \n",
       "502     21.0  396.90   9.08  20.6  \n",
       "503     21.0  396.90   5.64  23.9  \n",
       "504     21.0  393.45   6.48  22.0  \n",
       "505     21.0  396.90   7.88  11.9  \n",
       "\n",
       "[506 rows x 14 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1bfa809b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506, 14)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "bd0acc40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CRIM       0\n",
       "ZN         0\n",
       "INDUS      0\n",
       "CHAS       0\n",
       "NOX        0\n",
       "RM         0\n",
       "AGE        0\n",
       "DIS        0\n",
       "RAD        0\n",
       "TAX        0\n",
       "PTRATIO    0\n",
       "B          0\n",
       "LSTAT      0\n",
       "MEDV       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "9bf20de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x = df.drop(['MEDV'],axis=1)\n",
    "df_y = df['MEDV']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "07a4fa98",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(df_x, df_y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6ac11461",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the linear regression model\n",
    "reg = LinearRegression()\n",
    "reg.fit(x_train, y_train)\n",
    "lin_y_pred = reg.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b52d96fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error:  23.380836480270055\n",
      "Accuracy of model:  76.61916351972994 %\n"
     ]
    }
   ],
   "source": [
    "mse = mean_squared_error(y_test, lin_y_pred)\n",
    "print(\"Mean Squared Error: \", mse)\n",
    "print(\"Accuracy of model: \", 100-mse,'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "afddd7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we are using sequential model where layers are stacked one after another, \n",
    "#output of previous layer is given to as input to next layer\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import *\n",
    "\n",
    "#in this function we will define our model such as how many layers are present\n",
    "def pricepredictionmodel():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(128, input_shape=(13, ), activation='relu', name='dense_1'))\n",
    "    model.add(Dense(64, activation='relu', name='dense_2'))\n",
    "    model.add(Dense(1, activation='linear', name='dense_output'))\n",
    "    model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c62e3d6c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "101/101 [==============================] - 1s 4ms/step - loss: 112.6344 - mae: 7.8777 - val_loss: 138.5771 - val_mae: 9.9216\n",
      "Epoch 2/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 105.2236 - mae: 7.7492 - val_loss: 82.8056 - val_mae: 6.1145\n",
      "Epoch 3/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 61.1602 - mae: 5.8121 - val_loss: 86.8990 - val_mae: 6.3814\n",
      "Epoch 4/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 61.0531 - mae: 6.0039 - val_loss: 202.5720 - val_mae: 13.2080\n",
      "Epoch 5/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 60.6153 - mae: 5.7577 - val_loss: 50.6726 - val_mae: 5.1108\n",
      "Epoch 6/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 51.5630 - mae: 5.4485 - val_loss: 127.4762 - val_mae: 9.1416\n",
      "Epoch 7/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 52.9147 - mae: 5.6317 - val_loss: 61.0536 - val_mae: 5.1802\n",
      "Epoch 8/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 58.9780 - mae: 5.9104 - val_loss: 44.4122 - val_mae: 4.7441\n",
      "Epoch 9/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 44.7627 - mae: 5.1729 - val_loss: 48.2872 - val_mae: 5.8510\n",
      "Epoch 10/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 52.3480 - mae: 5.3994 - val_loss: 78.0875 - val_mae: 8.1379\n",
      "Epoch 11/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 55.1704 - mae: 5.6477 - val_loss: 43.7512 - val_mae: 4.7022\n",
      "Epoch 12/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 64.8634 - mae: 5.9343 - val_loss: 71.1679 - val_mae: 7.7539\n",
      "Epoch 13/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 48.5183 - mae: 5.2546 - val_loss: 62.6742 - val_mae: 7.1296\n",
      "Epoch 14/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 42.8617 - mae: 4.9446 - val_loss: 40.8617 - val_mae: 4.6065\n",
      "Epoch 15/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 56.6314 - mae: 5.3435 - val_loss: 40.2380 - val_mae: 4.4180\n",
      "Epoch 16/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 60.8095 - mae: 5.9084 - val_loss: 39.8250 - val_mae: 5.0103\n",
      "Epoch 17/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 38.3894 - mae: 4.7893 - val_loss: 47.3562 - val_mae: 5.8472\n",
      "Epoch 18/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 38.9917 - mae: 4.7052 - val_loss: 50.0442 - val_mae: 4.7254\n",
      "Epoch 19/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 58.5279 - mae: 5.7067 - val_loss: 76.6307 - val_mae: 8.0913\n",
      "Epoch 20/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 48.8489 - mae: 5.3075 - val_loss: 79.1914 - val_mae: 7.4492\n",
      "Epoch 21/100\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 44.2357 - mae: 5.0636 - val_loss: 42.7371 - val_mae: 4.9506\n",
      "Epoch 22/100\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 47.1894 - mae: 5.1880 - val_loss: 36.9133 - val_mae: 4.3987\n",
      "Epoch 23/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 39.2802 - mae: 4.5660 - val_loss: 36.7290 - val_mae: 4.5975\n",
      "Epoch 24/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 41.6436 - mae: 4.9185 - val_loss: 43.8135 - val_mae: 4.8727\n",
      "Epoch 25/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 40.2678 - mae: 4.8185 - val_loss: 62.0990 - val_mae: 6.9679\n",
      "Epoch 26/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 37.6398 - mae: 4.4900 - val_loss: 43.1840 - val_mae: 4.3724\n",
      "Epoch 27/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 38.2645 - mae: 4.4715 - val_loss: 81.1350 - val_mae: 7.0270\n",
      "Epoch 28/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 36.5370 - mae: 4.3761 - val_loss: 37.3113 - val_mae: 4.7151\n",
      "Epoch 29/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 34.6206 - mae: 4.2797 - val_loss: 55.6213 - val_mae: 6.3140\n",
      "Epoch 30/100\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 35.8465 - mae: 4.4250 - val_loss: 45.9386 - val_mae: 4.4297\n",
      "Epoch 31/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 38.9395 - mae: 4.6630 - val_loss: 52.0279 - val_mae: 5.0949\n",
      "Epoch 32/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 38.2094 - mae: 4.6666 - val_loss: 95.8958 - val_mae: 7.5383\n",
      "Epoch 33/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 42.2750 - mae: 4.9502 - val_loss: 43.5285 - val_mae: 4.4409\n",
      "Epoch 34/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 41.4194 - mae: 4.8168 - val_loss: 44.4012 - val_mae: 4.6791\n",
      "Epoch 35/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 43.8789 - mae: 5.0232 - val_loss: 52.5909 - val_mae: 5.0968\n",
      "Epoch 36/100\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 58.7694 - mae: 5.8060 - val_loss: 54.9354 - val_mae: 5.8684\n",
      "Epoch 37/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 49.8899 - mae: 5.1927 - val_loss: 52.0564 - val_mae: 6.2837\n",
      "Epoch 38/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 33.4221 - mae: 4.1774 - val_loss: 35.4601 - val_mae: 4.0803\n",
      "Epoch 39/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 44.5044 - mae: 4.9376 - val_loss: 38.2349 - val_mae: 4.0495\n",
      "Epoch 40/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 37.0579 - mae: 4.3898 - val_loss: 35.5948 - val_mae: 4.0749\n",
      "Epoch 41/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 34.2418 - mae: 4.2743 - val_loss: 57.4828 - val_mae: 6.6547\n",
      "Epoch 42/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 33.6519 - mae: 4.3587 - val_loss: 47.0785 - val_mae: 5.6692\n",
      "Epoch 43/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 28.7513 - mae: 3.9453 - val_loss: 32.9965 - val_mae: 4.1200\n",
      "Epoch 44/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 31.6183 - mae: 3.9888 - val_loss: 57.3631 - val_mae: 6.7624\n",
      "Epoch 45/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 33.6550 - mae: 4.2779 - val_loss: 57.5395 - val_mae: 6.7615\n",
      "Epoch 46/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 35.8207 - mae: 4.4178 - val_loss: 35.9335 - val_mae: 4.3316\n",
      "Epoch 47/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 35.9985 - mae: 4.4580 - val_loss: 35.2659 - val_mae: 3.8562\n",
      "Epoch 48/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 31.5216 - mae: 4.1400 - val_loss: 35.4892 - val_mae: 4.0495\n",
      "Epoch 49/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 31.0860 - mae: 4.1480 - val_loss: 40.3954 - val_mae: 5.1846\n",
      "Epoch 50/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 30.7206 - mae: 4.0775 - val_loss: 105.9116 - val_mae: 9.1771\n",
      "Epoch 51/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 31.4892 - mae: 4.2635 - val_loss: 30.8066 - val_mae: 3.9726\n",
      "Epoch 52/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 32.2747 - mae: 4.1746 - val_loss: 38.8676 - val_mae: 4.0317\n",
      "Epoch 53/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 28.5485 - mae: 3.9079 - val_loss: 35.6873 - val_mae: 4.6567\n",
      "Epoch 54/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 26.0942 - mae: 3.7924 - val_loss: 30.3624 - val_mae: 3.8767\n",
      "Epoch 55/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 32.2304 - mae: 4.3921 - val_loss: 32.4290 - val_mae: 4.4271\n",
      "Epoch 56/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 31.2155 - mae: 4.0915 - val_loss: 36.8016 - val_mae: 5.0224\n",
      "Epoch 57/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 24.6102 - mae: 3.5688 - val_loss: 40.1363 - val_mae: 5.2925\n",
      "Epoch 58/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 31.7165 - mae: 4.2515 - val_loss: 53.6123 - val_mae: 6.3207\n",
      "Epoch 59/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 24.7857 - mae: 3.6876 - val_loss: 33.6017 - val_mae: 4.7209\n",
      "Epoch 60/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 28.2343 - mae: 3.8973 - val_loss: 33.0652 - val_mae: 4.7133\n",
      "Epoch 61/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101/101 [==============================] - 0s 2ms/step - loss: 26.1788 - mae: 3.7863 - val_loss: 29.4128 - val_mae: 4.3789\n",
      "Epoch 62/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 24.3333 - mae: 3.5556 - val_loss: 28.4444 - val_mae: 4.1045\n",
      "Epoch 63/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 28.2888 - mae: 3.8416 - val_loss: 32.4056 - val_mae: 3.7474\n",
      "Epoch 64/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 30.0454 - mae: 4.0668 - val_loss: 30.6465 - val_mae: 4.3954\n",
      "Epoch 65/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 27.4540 - mae: 3.7926 - val_loss: 44.0518 - val_mae: 5.7007\n",
      "Epoch 66/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 24.2521 - mae: 3.5777 - val_loss: 31.1327 - val_mae: 3.9656\n",
      "Epoch 67/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 26.5365 - mae: 3.8403 - val_loss: 31.9699 - val_mae: 4.6487\n",
      "Epoch 68/100\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 24.6489 - mae: 3.7908 - val_loss: 26.4575 - val_mae: 3.4712\n",
      "Epoch 69/100\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 22.3009 - mae: 3.4924 - val_loss: 26.3071 - val_mae: 3.8528\n",
      "Epoch 70/100\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 23.4065 - mae: 3.5212 - val_loss: 29.6700 - val_mae: 4.5024\n",
      "Epoch 71/100\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 22.6782 - mae: 3.4004 - val_loss: 28.5811 - val_mae: 4.2746\n",
      "Epoch 72/100\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 22.8587 - mae: 3.4411 - val_loss: 63.8879 - val_mae: 7.0688\n",
      "Epoch 73/100\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 34.7083 - mae: 4.4067 - val_loss: 38.0671 - val_mae: 5.0050\n",
      "Epoch 74/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 21.6826 - mae: 3.3223 - val_loss: 25.7440 - val_mae: 3.9558\n",
      "Epoch 75/100\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 22.1706 - mae: 3.3892 - val_loss: 52.9887 - val_mae: 6.3895\n",
      "Epoch 76/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 22.9361 - mae: 3.4734 - val_loss: 33.0809 - val_mae: 4.7642\n",
      "Epoch 77/100\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 20.8726 - mae: 3.3039 - val_loss: 29.9487 - val_mae: 4.1089\n",
      "Epoch 78/100\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 22.2160 - mae: 3.4612 - val_loss: 23.1036 - val_mae: 3.3990\n",
      "Epoch 79/100\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 21.0466 - mae: 3.2636 - val_loss: 24.9719 - val_mae: 3.8307\n",
      "Epoch 80/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 25.5339 - mae: 3.7367 - val_loss: 26.0271 - val_mae: 3.4268\n",
      "Epoch 81/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 23.5486 - mae: 3.6000 - val_loss: 23.6211 - val_mae: 3.5072\n",
      "Epoch 82/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 21.7386 - mae: 3.3517 - val_loss: 25.6950 - val_mae: 4.1674\n",
      "Epoch 83/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 27.9439 - mae: 3.9912 - val_loss: 23.2833 - val_mae: 3.3618\n",
      "Epoch 84/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 23.6878 - mae: 3.6234 - val_loss: 30.9601 - val_mae: 4.5997\n",
      "Epoch 85/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 21.3482 - mae: 3.4059 - val_loss: 22.0334 - val_mae: 3.5069\n",
      "Epoch 86/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 19.6893 - mae: 3.1616 - val_loss: 21.5669 - val_mae: 3.2367\n",
      "Epoch 87/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 19.9044 - mae: 3.2753 - val_loss: 20.3008 - val_mae: 3.3364\n",
      "Epoch 88/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 23.5494 - mae: 3.5134 - val_loss: 18.9366 - val_mae: 3.2600\n",
      "Epoch 89/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 22.0279 - mae: 3.4275 - val_loss: 20.3604 - val_mae: 3.2573\n",
      "Epoch 90/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 22.1404 - mae: 3.5152 - val_loss: 25.9433 - val_mae: 3.7976\n",
      "Epoch 91/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 24.4514 - mae: 3.5762 - val_loss: 25.0802 - val_mae: 3.9313\n",
      "Epoch 92/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 20.8229 - mae: 3.3002 - val_loss: 24.6087 - val_mae: 3.5118\n",
      "Epoch 93/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 20.9566 - mae: 3.2760 - val_loss: 23.7803 - val_mae: 3.2770\n",
      "Epoch 94/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 20.7565 - mae: 3.3316 - val_loss: 17.4198 - val_mae: 3.0202\n",
      "Epoch 95/100\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 23.9842 - mae: 3.5109 - val_loss: 30.3935 - val_mae: 3.9067\n",
      "Epoch 96/100\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 19.3068 - mae: 3.1837 - val_loss: 23.9440 - val_mae: 3.8957\n",
      "Epoch 97/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 19.6662 - mae: 3.0841 - val_loss: 17.9597 - val_mae: 3.1211\n",
      "Epoch 98/100\n",
      "101/101 [==============================] - 0s 2ms/step - loss: 16.9495 - mae: 2.9922 - val_loss: 22.3585 - val_mae: 3.2204\n",
      "Epoch 99/100\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 19.8304 - mae: 3.1221 - val_loss: 18.5882 - val_mae: 3.2001\n",
      "Epoch 100/100\n",
      "101/101 [==============================] - 0s 3ms/step - loss: 23.8335 - mae: 3.5434 - val_loss: 18.3003 - val_mae: 3.1764\n"
     ]
    }
   ],
   "source": [
    "#now we will train our model so we need to call the function\n",
    "model = pricepredictionmodel()\n",
    "#The batch size is a number of samples processed before the model is updated.\n",
    "#verbose is the choice that how you want to see the output of your Nural Network while it's training. If you set verbose = 0, It will show nothing\n",
    "model_history = model.fit(x_train, y_train, epochs = 100, batch_size=4, verbose=1, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "240aba47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([32.65503184, 28.0934953 , 18.02901829, 21.47671576, 18.8254387 ,\n",
       "       19.87997758, 32.42014863, 18.06597765, 24.42277848, 27.00977832,\n",
       "       27.04081017, 28.75196794, 21.15677699, 26.85200196, 23.38835945,\n",
       "       20.66241266, 17.33082198, 38.24813601, 30.50550873,  8.74436733,\n",
       "       20.80203902, 16.26328126, 25.21805656, 24.85175752, 31.384365  ,\n",
       "       10.71311063, 13.80434635, 16.65930389, 36.52625779, 14.66750528,\n",
       "       21.12114902, 13.95558618, 43.16210242, 17.97539649, 21.80116017,\n",
       "       20.58294808, 17.59938821, 27.2212319 ,  9.46139365, 19.82963781,\n",
       "       24.30751863, 21.18528812, 29.57235682, 16.3431752 , 19.31483171,\n",
       "       14.56343172, 39.20885479, 18.10887551, 25.91223267, 20.33018802,\n",
       "       25.16282007, 24.42921237, 25.07123258, 26.6603279 ,  4.56151258,\n",
       "       24.0818735 , 10.88682673, 26.88926656, 16.85598381, 35.88704363,\n",
       "       19.55733853, 27.51928921, 16.58436103, 18.77551029, 11.13872875,\n",
       "       32.36392607, 36.72833773, 21.95924582, 24.57949647, 25.14868695,\n",
       "       23.42841301,  6.90732017, 16.56298149, 20.41940517, 20.80403418,\n",
       "       21.54219598, 33.85383463, 27.94645899, 25.17281456, 34.65883942,\n",
       "       18.62487738, 23.97375565, 34.6419296 , 13.34754896, 20.71097982,\n",
       "       30.0803549 , 17.13421671, 24.30528434, 19.25576671, 16.98006722,\n",
       "       27.00622638, 41.85509074, 14.11131512, 23.25736073, 14.66302672,\n",
       "       21.86977175, 23.02527624, 29.0899182 , 37.11937872, 20.53271022,\n",
       "       17.36840034, 17.71399314])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "84bafc26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step\n",
      "Predicted Output:  [[32.877636 ]\n",
      " [25.546436 ]\n",
      " [16.48689  ]\n",
      " [22.498505 ]\n",
      " [24.227287 ]\n",
      " [20.248507 ]\n",
      " [28.887444 ]\n",
      " [18.37785  ]\n",
      " [19.933424 ]\n",
      " [24.72063  ]\n",
      " [26.422567 ]\n",
      " [27.822983 ]\n",
      " [18.788597 ]\n",
      " [21.237806 ]\n",
      " [21.273586 ]\n",
      " [20.295753 ]\n",
      " [11.693295 ]\n",
      " [34.996998 ]\n",
      " [25.773527 ]\n",
      " [15.006518 ]\n",
      " [20.69877  ]\n",
      " [18.1634   ]\n",
      " [22.653399 ]\n",
      " [26.150232 ]\n",
      " [30.104706 ]\n",
      " [15.332846 ]\n",
      " [11.4572935]\n",
      " [18.932253 ]\n",
      " [36.66733  ]\n",
      " [12.870041 ]\n",
      " [21.975382 ]\n",
      " [14.31539  ]\n",
      " [44.502026 ]\n",
      " [15.30054  ]\n",
      " [18.902138 ]\n",
      " [19.903774 ]\n",
      " [16.027266 ]\n",
      " [32.51696  ]\n",
      " [10.575177 ]\n",
      " [16.052402 ]\n",
      " [21.548092 ]\n",
      " [24.268364 ]\n",
      " [27.093689 ]\n",
      " [14.409877 ]\n",
      " [14.016468 ]\n",
      " [14.233967 ]\n",
      " [45.874332 ]\n",
      " [14.97346  ]\n",
      " [20.961725 ]\n",
      " [15.336845 ]\n",
      " [20.580326 ]\n",
      " [18.875511 ]\n",
      " [31.213581 ]\n",
      " [19.77702  ]\n",
      " [13.092795 ]\n",
      " [23.351286 ]\n",
      " [ 8.308769 ]\n",
      " [27.982075 ]\n",
      " [17.690575 ]\n",
      " [34.248135 ]\n",
      " [17.529114 ]\n",
      " [27.321865 ]\n",
      " [13.534411 ]\n",
      " [16.663996 ]\n",
      " [ 7.542953 ]\n",
      " [40.261208 ]\n",
      " [37.91562  ]\n",
      " [21.63572  ]\n",
      " [22.280348 ]\n",
      " [21.586979 ]\n",
      " [25.50434  ]\n",
      " [ 8.747114 ]\n",
      " [17.246246 ]\n",
      " [19.262768 ]\n",
      " [18.724146 ]\n",
      " [20.960987 ]\n",
      " [44.760777 ]\n",
      " [23.139666 ]\n",
      " [30.003437 ]\n",
      " [32.54217  ]\n",
      " [18.592869 ]\n",
      " [22.296974 ]\n",
      " [30.855    ]\n",
      " [16.208471 ]\n",
      " [22.952244 ]\n",
      " [25.29557  ]\n",
      " [16.080315 ]\n",
      " [26.957527 ]\n",
      " [19.256508 ]\n",
      " [17.71354  ]\n",
      " [27.782242 ]\n",
      " [43.757336 ]\n",
      " [15.615171 ]\n",
      " [20.784563 ]\n",
      " [14.081449 ]\n",
      " [19.975489 ]\n",
      " [21.566492 ]\n",
      " [22.580158 ]\n",
      " [35.493893 ]\n",
      " [19.508196 ]\n",
      " [13.614771 ]\n",
      " [14.296769 ]]\n"
     ]
    }
   ],
   "source": [
    "#training is complited \n",
    "#a = y_pred\n",
    "dnn_y_pred = model.predict(x_test)\n",
    "print(\"Predicted Output: \", dnn_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "607e8c8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error:  18.30026214754418\n",
      "Accuracy of model:  81.69973785245583 %\n"
     ]
    }
   ],
   "source": [
    "mse = mean_squared_error(y_test, dnn_y_pred)\n",
    "print(\"Mean Squared Error: \", mse)\n",
    "print(\"Accuracy of model: \", 100-mse,'%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
